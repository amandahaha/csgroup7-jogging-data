class("test")
install.packages("rvest")
class(is.integer(2))
class(integer(2))
class(integer(T))
class(integer(12))
class(integer(12.5))
class(is.integer(12.5))
class(is.integer(.35))
is.integer(12.5)
as.integer(T)
as.integer(F)
as.integer(q)
1+2
1-2
sqrt(2)
x+y
y <- 2
X+y
x <-1
y <- 2
x+y
x+y
exists(x)
exists("x")
x <- 3
y <- 2
x+y
x <- 9
y <- 2
x+y
exists("x")
library(rvest)
page.source <- read_html("http://admin-apps.webofknowledge.com/JCR/JCR?RQ=CI
number.block <- html_nodes(page.source, "hr+ table .textbold td")
head(number.block)
library(rvest)
page.source <- read_html("http://admin-apps.webofknowledge.com/JCR/JCR?RQ=CI
number.block <- html_nodes(page.source, "hr+ table .textbold td")
library(rvest)
page.source <- read_html("http://admin-apps.webofknowledge.com/JCR/JCR?RQ=CI")
number.block <- html_nodes(page.source, "hr+ table .textbold td")
head(number.block)
library(rvest)
page.source <- read_html("http://admin-apps.webofknowledge.com/JCR/JCR?RQ=CI")
number.block <- html_nodes(page.source, "hr+ table .textbold td")
head(number.block)
head(number.block)
library(rvest)
page.source <- read_html("http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&rank=1&journal=ACTA+GEOGR+SLOV")
number.block <- html_nodes(page.source, "h3")
head(number.block)
library(rvest)
page.source <- read_html("http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&rank=1&journal=ACTA+GEOGR+SLOV")
number.block <- html_nodes(page.source, "h3")
head(number.block)
install.packages("httr")
install.packages("httr")
library(httr)
r <- GET("http://httpbin.org/get")
r
status_code(r)
headers(r)
r <- GET("http://admin-apps.webofknowledge.com/JCR/JCR?RQ=CITE_CITING&journal=ACTA+GEOGR+SLOV&rank=1&cursor=1")
r
r$status_code
content(r, "text")
library(rvest)
library(xml2)
library(rvest)
s <- html_session("http://had.co.nz")
t <- s %>% jump_to("thesis/")
t <- s %>% jump_to("thesis/")
t <- s %>% jump_to("thesis/,http://had.co.nz")
s %>% jump_to("hadley-wickham.jpg") %>% jump_to("/") %>% session_history()
s %>% jump_to("hadley-wickham.jpg") %>% back() %>% session_history()
s %>% follow_link(css = "p a")
library(xml2)
library(rvest)
s <- html_session("http://admin.webofknowledge.com/SessionError.cgi?CSID=&DestApp=JCR&Error=SESSION+NOT+ACTIVE")
s %>% follow_link(css = "p a")
S
s
setwd help
help(setwd)
getwd()
library(XML)
library(httr)
library(bitops)
library(RCurl)
#get downloaded page path
urlpath <- "https://www.ptt.cc/bbs/movie/index.html"
#where to put the downloaded page
temp <- getURL(urlpath, encoding="big5")
Sys.getlocale("LC_ALL)
Sys.getlocale("LC_ALL")
Sys.getlocale("LC_ALL")
source('C:/Users/Ji-Yu Huang/Desktop/group7/R/firstR.r', echo=TRUE)
title
source('C:/Users/Ji-Yu Huang/Desktop/group7/R/firstR.r', echo=TRUE)
library(XML)
library(httr)
library(bitops)
library(RCurl)
#get downloaded page path
urlpath <- "https://www.ptt.cc/bbs/movie/index.html"
#where to put the downloaded page
temp <- getURL(urlpath, encoding="big5")
#xml
xmldoc  <- htmlParse(temp)
title = xpathSApply(xmldoc, "//div[@class=\"title\"]", xmlValue)
#title <- xpathSApply(xmldoc,"//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"title\", \" \" ))]",xmlValue)
url = xpathSApply(xmldoc, "//div[@class=\"title\"]//a@href", xmlValue)
#frame..??
alldata = data.frame(title,url)
library(XML)
library(httr)
library(bitops)
library(RCurl)
#get downloaded page path
urlpath <- "https://www.ptt.cc/bbs/movie/index.html"
#where to put the downloaded page
temp <- getURL(urlpath, encoding="big5")
#xml
xmldoc  <- htmlParse(temp)
title = xpathSApply(xmldoc, "//div[@class=\"title\"]", xmlValue)
#title <- xpathSApply(xmldoc,"//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"title\", \" \" ))]",xmlValue)
url = xpathSApply(xmldoc, "//div[@class=\"title\"]/a//@href", xmlValue)
#frame..??
alldata = data.frame(title,url)
library(XML)
library(httr)
library(bitops)
library(RCurl)
#get downloaded page path
urlpath <- "https://www.ptt.cc/bbs/movie/index.html"
#where to put the downloaded page
temp <- getURL(urlpath, encoding="big5")
#xml
xmldoc  <- htmlParse(temp)
author  <- xpathSApply(xmldoc, "//div[@class='author']", xmlValue)
path    <- xpathSApply(xmldoc, "//div[@class='title']/a//@href")
date    <- xpathSApply(xmldoc, "//div[@class='date']", xmlValue)
response<- xpathSApply(xmldoc, "//div[@class='nrec']", xmlValue)
alldata = data.frame(title,url)
library(XML)
library(httr)
library(bitops)
library(RCurl)
#get downloaded page path
urlpath <- "https://www.ptt.cc/bbs/movie/index.html"
#where to put the downloaded page
temp <- getURL(urlpath, encoding="big5")
#xml
xmldoc  <- htmlParse(temp)
author  <- xpathSApply(xmldoc, "//div[@class='author']", xmlValue)
path    <- xpathSApply(xmldoc, "//div[@class='title']/a//@href")
date    <- xpathSApply(xmldoc, "//div[@class='date']", xmlValue)
response<- xpathSApply(xmldoc, "//div[@class='nrec']", xmlValue)
library(XML)
library(httr)
library(bitops)
library(RCurl)
#get downloaded page path
urlpath <- "https://www.ptt.cc/bbs/movie/index.html"
#where to put the downloaded page
temp <- getURL(urlpath, encoding="big5")
#xml
xmldoc  <- htmlParse(temp)
author  <- xpathSApply(xmldoc, "//div[@class='author']", xmlValue)
path    <- xpathSApply(xmldoc, "//div[@class='title']/a//@href")
date    <- xpathSApply(xmldoc, "//div[@class='date']", xmlValue)
response<- xpathSApply(xmldoc, "//div[@class='nrec']", xmlValue)
alldata <- data.frame(title, author, path, date, response)
library(XML)
library(httr)
library(bitops)
library(RCurl)
#get downloaded page path
urlpath = "https://www.ptt.cc/bbs/movie/index.html"
#where to put the downloaded page
temp = getURL(urlpath, encoding="big5")
#xml
xmldoc  = htmlParse(temp)
author  = xpathSApply(xmldoc, "//div[@class='author']", xmlValue)
path    = xpathSApply(xmldoc, "//div[@class='title']/a//@href")
date    = xpathSApply(xmldoc, "//div[@class='date']", xmlValue)
response= xpathSApply(xmldoc, "//div[@class='nrec']", xmlValue)
alldata = data.frame(title, author, path, date, response)
library(XML)
library(httr)
library(bitops)
library(RCurl)
#get downloaded page path
suburlpath = "https://www.ptt.cc/bbs/movie/index"
startNo = 4665
endNo = 4668
for (i in c(startNo:endNo))  # c is array
{
urlpath = paste(suburlpath,i,".html",sep="")
#where to put the downloaded page
temp = getURL(urlpath, encoding="big5")
#xml parse
xmldoc  = htmlParse(temp)
#srape the data
author  = xpathSApply(xmldoc, "//div[@class='author']", xmlValue)
path    = xpathSApply(xmldoc, "//div[@class='title']/a//@href")
date    = xpathSApply(xmldoc, "//div[@class='date']", xmlValue)
response= xpathSApply(xmldoc, "//div[@class='nrec']", xmlValue)
#put in together
alldata = data.frame(title, author, path, date, response)
}
library(XML)
library(httr)
library(bitops)
library(RCurl)
#get downloaded page path
suburlpath = "https://www.ptt.cc/bbs/movie/index"
startNo = 4665
endNo = 4667
for (i in c(startNo:endNo))  # c is array
{
urlpath = paste(suburlpath,i,".html",sep="")
#where to put the downloaded page
temp = getURL(urlpath, encoding="big5")
#xml parse
xmldoc  = htmlParse(temp)
#srape the data
author  = xpathSApply(xmldoc, "//div[@class='author']", xmlValue)
path    = xpathSApply(xmldoc, "//div[@class='title']/a//@href")
date    = xpathSApply(xmldoc, "//div[@class='date']", xmlValue)
response= xpathSApply(xmldoc, "//div[@class='nrec']", xmlValue)
#put in together
}
alldata = data.frame(title, author, path, date, response)
library(XML)
library(httr)
library(bitops)
library(RCurl)
#get downloaded page path
suburlpath = "https://www.ptt.cc/bbs/movie/index"
startNo = 4665
endNo = 4667
for (i in c(startNo:endNo))  # c is array
{
urlpath = paste(suburlpath,i,".html",sep="")
#where to put the downloaded page
temp = getURL(urlpath, encoding="big5")
#xml parse
xmldoc  = htmlParse(temp)
#srape the data
author  = xpathSApply(xmldoc, "//div[@class='author']", xmlValue)
path    = xpathSApply(xmldoc, "//div[@class='title']/a//@href")
date    = xpathSApply(xmldoc, "//div[@class='date']", xmlValue)
response= xpathSApply(xmldoc, "//div[@class='nrec']", xmlValue)
#put in together
alldata = data.frame(title, author, path, date, response)
}
library(XML)
library(httr)
library(bitops)
library(RCurl)
#get downloaded page path
suburlpath = "https://www.ptt.cc/bbs/movie/index"
startNo = 4649
endNo = 4667
for (i in c(startNo:endNo))  # c is array
{
urlpath = paste(suburlpath,i,".html",sep="")
#where to put the downloaded page
temp = getURL(urlpath, encoding="big5")
#xml parse
xmldoc  = htmlParse(temp)
#srape the data
author  = xpathSApply(xmldoc, "//div[@class='author']", xmlValue)
path    = xpathSApply(xmldoc, "//div[@class='title']/a//@href")
date    = xpathSApply(xmldoc, "//div[@class='date']", xmlValue)
response= xpathSApply(xmldoc, "//div[@class='nrec']", xmlValue)
#put in together
alldata = data.frame(title, author, path, date, response)
}
i
library(XML)
library(httr)
library(bitops)
library(RCurl)
#get downloaded page path
suburlpath = "https://www.ptt.cc/bbs/movie/index"
startNo = 4649
endNo = 4667
#first is none array
alltitle = data.frame()
for (i in c(startNo:endNo))  # c is array
{
urlpath = paste(suburlpath,i,".html",sep="")
#where to put the downloaded page
temp = getURL(urlpath, encoding="big5")
#xml parse
xmldoc  = htmlParse(temp)
#srape the data
author  = xpathSApply(xmldoc, "//div[@class='author']", xmlValue)
path    = xpathSApply(xmldoc, "//div[@class='title']/a//@href")
date    = xpathSApply(xmldoc, "//div[@class='date']", xmlValue)
response= xpathSApply(xmldoc, "//div[@class='nrec']", xmlValue)
#put in together
alltitle = cbind(alltitle,data.frame(title))
#alldata = data.frame(title, author, path, date, response)
}
i
data.frame(title)
x = data.frame(title)
View(x)
View(alltitle)
library(XML)
library(httr)
library(bitops)
library(RCurl)
#get downloaded page path
suburlpath = "https://www.ptt.cc/bbs/movie/index"
startNo = 4649
endNo = 4667
#first is none array
alltitle = data.frame()
for (i in c(startNo:endNo))  # c is array
{
urlpath = paste(suburlpath,i,".html",sep="")
#where to put the downloaded page
temp = getURL(urlpath, encoding="big5")
#xml parse
xmldoc  = htmlParse(temp)
#srape the data
author  = xpathSApply(xmldoc, "//div[@class='author']", xmlValue)
path    = xpathSApply(xmldoc, "//div[@class='title']/a//@href")
date    = xpathSApply(xmldoc, "//div[@class='date']", xmlValue)
response= xpathSApply(xmldoc, "//div[@class='nrec']", xmlValue)
#put in together
alltitle = rbind(alltitle,data.frame(title))
#alldata = data.frame(title, author, path, date, response)
}
View(alltitle)
View(alldata)
View(alltitle)
library(XML)
library(httr)
library(bitops)
library(RCurl)
#get downloaded page path
suburlpath = "https://www.ptt.cc/bbs/movie/index"
startNo = 4649
endNo = 4667
#first is none array
alltitle = data.frame()
allpath = data.frame()
alldate = data.frame()
for (i in c(startNo:endNo))  # c is array
{
urlpath = paste(suburlpath,i,".html",sep="")
#where to put the downloaded page
temp = getURL(urlpath, encoding="big5")
#xml parse
xmldoc  = htmlParse(temp)
#srape the data
author  = xpathSApply(xmldoc, "//div[@class='author']", xmlValue)
url    = xpathSApply(xmldoc, "//div[@class='title']/a//@href")
date    = xpathSApply(xmldoc, "//div[@class='date']", xmlValue)
response= xpathSApply(xmldoc, "//div[@class='nrec']", xmlValue)
result = tryCatch({
alltitle = rbind(alltitle,data.frame(title))
print(url)
},error = function(err) {
print(url)
}
)
#put in together
alltitle = rbind(alltitle,data.frame(title))
#alldata = data.frame(title, author, path, date, response)
}
View(alldata)
View(alltitle)
library(XML)
library(httr)
library(bitops)
library(RCurl)
#get downloaded page path
suburlpath = "https://www.ptt.cc/bbs/movie/index"
startNo = 4649
endNo = 4650
#first is none array
alltitle = data.frame()
allpath = data.frame()
alldate = data.frame()
for (i in c(startNo:endNo))  # c is array
{
urlpath = paste(suburlpath,i,".html",sep="")
#where to put the downloaded page
temp = getURL(urlpath, encoding="big5")
#xml parse
xmldoc  = htmlParse(temp)
#srape the data
author  = xpathSApply(xmldoc, "//div[@class='author']", xmlValue)
url    = xpathSApply(xmldoc, "//div[@class='title']/a//@href")
date    = xpathSApply(xmldoc, "//div[@class='date']", xmlValue)
response= xpathSApply(xmldoc, "//div[@class='nrec']", xmlValue)
result = tryCatch({
alltitle = rbind(alltitle,data.frame(title))
print(url)
}
error = function(err) {
print(url)
}
)
#put in together
alltitle = rbind(alltitle,data.frame(title))
#alldata = data.frame(title, author, path, date, response)
}
library(XML)
library(httr)
library(bitops)
library(RCurl)
#get downloaded page path
suburlpath = "https://www.ptt.cc/bbs/movie/index"
startNo = 4649
endNo = 4650
#first is none array
alltitle = data.frame()
allpath = data.frame()
alldate = data.frame()
for (i in c(startNo:endNo))  # c is array
{
urlpath = paste(suburlpath,i,".html",sep="")
#where to put the downloaded page
temp = getURL(urlpath, encoding="big5")
#xml parse
xmldoc  = htmlParse(temp)
#srape the data
author  = xpathSApply(xmldoc, "//div[@class='author']", xmlValue)
url    = xpathSApply(xmldoc, "//div[@class='title']/a//@href")
date    = xpathSApply(xmldoc, "//div[@class='date']", xmlValue)
response= xpathSApply(xmldoc, "//div[@class='nrec']", xmlValue)
result = tryCatch({
alltitle = rbind(alltitle,data.frame(title))
print(url)
},error = function(err) {
print(url)
}
)
#put in together
alltitle = rbind(alltitle,data.frame(title))
#alldata = data.frame(title, author, path, date, response)
}
setwd("C:/Users/Ji-Yu Huang/Desktop/csgroup7-jogging-data/demoslide")
install.packages("rmarkdown")
install.packages("leaflet")
library(leaflet)
